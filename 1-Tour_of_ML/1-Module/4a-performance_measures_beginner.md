# Understanding the Math Behind Performance Measures 


## ğŸ”· 1. Error Rate (Classification)

**Formula:**

```
Error rate = Number of incorrect predictions / Total number of predictions
```

### ğŸ§  What does it mean?

You're dividing:
- The number of wrong answers your model gave,
- by the total number of questions it was asked.

This gives you a **proportion** (or percentage) of how often the model makes mistakes.

### ğŸ§® Why this makes sense:

This is like taking a test and figuring out how many questions you got wrong out of the total.  
If you got 2 wrong out of 10, your error rate is 2 Ã· 10 = 0.2 or 20%.

---

## âœ… 2. Accuracy

**Formula:**

```
Accuracy = 1 - Error rate
```

Or:

```
Accuracy = Number of correct predictions / Total number of predictions
```

### ğŸ§  What does it mean?

This is the flip side of error rate.  
If the model is wrong 20% of the time, then itâ€™s right 80% of the time.

---

## ğŸ¯ 3. 0-1 Loss (Classification)

**Idea:**

- If prediction is correct â†’ loss = 0
- If prediction is wrong â†’ loss = 1

Average these losses to get the **expected 0-1 loss**.

### ğŸ§  Why this works:

This is like keeping score where every mistake costs 1 point and correct guesses cost 0.

---

## ğŸ“ˆ 4. Mean Squared Error (MSE) â€“ Regression

**Formula:**

```
MSE = (1 / N) * Î£ [ (Yáµ¢ - Å¶áµ¢) / Yáµ¢ ]Â²
```

Where:
- Yáµ¢ = the actual value
- Å¶áµ¢ = the predicted value
- N = number of examples

### ğŸ§  What does it mean?

For each prediction:
1. Find the error (Yáµ¢ - Å¶áµ¢)
2. Scale it by dividing by Yáµ¢
3. Square the result (to remove negatives and highlight big mistakes)
4. Average all squared values

### ğŸ§® Why square?

- Makes negative and positive errors both count
- **Big mistakes** hurt more (e.g. 10Â² = 100, but 2Â² = 4)

---

## ğŸ“ 5. L1 Loss (Mean Absolute Error)

**Formula:**

```
L1 Loss = (1 / N) * Î£ |(Yáµ¢ - Å¶áµ¢) / Yáµ¢|
```

### ğŸ§  What does it mean?

Instead of squaring, we just take the **absolute value** (how far off we are).

1. Find the error (Yáµ¢ - Å¶áµ¢)
2. Make it positive (absolute value)
3. Scale it
4. Average all the results

### ğŸ§® Why use absolute values?

- Treats all errors fairly, big or small
- **More resistant to outliers** (huge errors wonâ€™t explode the result)

---

## ğŸ§  Summary in Real Talk

- **Error rate**: How often are we wrong?
- **Accuracy**: How often are we right?
- **0-1 loss**: A simple way to score classification (1 point for every wrong guess).
- **MSE**: Think of it like yelling at your model for big mistakes â€” it makes them hurt more.
- **L1 Loss**: More chill â€” just tells the model how far off it is on average.
